{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5bffae77",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-25T15:50:44.789228Z",
     "iopub.status.busy": "2023-05-25T15:50:44.788376Z",
     "iopub.status.idle": "2023-05-25T15:51:00.017470Z",
     "shell.execute_reply": "2023-05-25T15:51:00.015860Z"
    },
    "papermill": {
     "duration": 15.247765,
     "end_time": "2023-05-25T15:51:00.021048",
     "exception": false,
     "start_time": "2023-05-25T15:50:44.773283",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /kaggle/input/mllibs/mllibs-0.0.9-py3-none-any.whl\r\n",
      "Installing collected packages: mllibs\r\n",
      "Successfully installed mllibs-0.0.9\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install /kaggle/input/mllibs/mllibs-0.0.9-py3-none-any.whl --force-reinstall "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac4026d2",
   "metadata": {
    "papermill": {
     "duration": 0.01237,
     "end_time": "2023-05-25T15:51:00.046453",
     "exception": false,
     "start_time": "2023-05-25T15:51:00.034083",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "![](https://i.imgur.com/IPboSfw.jpg)\n",
    "\n",
    "## <b><span style='color:#B6DA32'>1 | BACKGROUND</span></b>\n",
    "\n",
    "<div style=\"color:white;border-radius:8px;background-color:#323232;font-size:100%\">\n",
    "<p style=\"padding: 10px;color:white;\"><b><span style='color:#B6DA32; font-weight:bold'> 1.1 | TEXT ENCODING</span></b></p>\n",
    "</div>\n",
    "\n",
    "- In the previous notebook, **[sample eda notbook](https://www.kaggle.com/code/shtrausslearning/mllibs-sample-eda-notebook)**, we looking into ways we can explore our **numeric** and **categorical** data, utilising `hue` gives us valuable insight into how our data is distributed\n",
    "- When it comes to **data preprocessing**, most models will not be able to interpret text in our data, which is why we need to **encode** our data \n",
    "- The process of **text encoding** - process of converting mearning ful text into a number or vector representataion \n",
    "- We often group Bag of Words (**countvectoriser**), index (**labelencoder**), and binary based methods (**onehotencoding**) into a group called traditional approaches, whilst more advanced methods are reserved for methods which create a **numeric vector representation** for a particular word (generation of embeddings). These embeddings can then be utilised (eg. average for each document) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "079adcfb",
   "metadata": {
    "papermill": {
     "duration": 0.012885,
     "end_time": "2023-05-25T15:51:00.072224",
     "exception": false,
     "start_time": "2023-05-25T15:51:00.059339",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## <b><span style='color:#B6DA32'>2 | INTERPRETER SETUP</span></b>\n",
    "\n",
    "<div style=\"color:white;border-radius:8px;background-color:#323232;font-size:100%\">\n",
    "<p style=\"padding: 10px;color:white;\"><b><span style='color:#B6DA32; font-weight:bold'> 2.1 | USER INTERFACE\n",
    "</span></b></p>\n",
    "</div>\n",
    "\n",
    "<code>interface</code> allows us to automate the setup of mllibs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39b8c731",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-25T15:51:00.100204Z",
     "iopub.status.busy": "2023-05-25T15:51:00.099707Z",
     "iopub.status.idle": "2023-05-25T15:51:20.131108Z",
     "shell.execute_reply": "2023-05-25T15:51:20.129750Z"
    },
    "papermill": {
     "duration": 20.05061,
     "end_time": "2023-05-25T15:51:20.135488",
     "exception": false,
     "start_time": "2023-05-25T15:51:00.084878",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /usr/share/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "loading modules ...\n",
      "making module summary labels...\n",
      "done ...\n",
      "eda LogisticRegression() accuracy 1.0\n",
      "eda_colplot LogisticRegression() accuracy 1.0\n",
      "eda_plot LogisticRegression() accuracy 1.0\n",
      "loader LogisticRegression() accuracy 1.0\n",
      "make_folds LogisticRegression() accuracy 1.0\n",
      "nlp_embedding LogisticRegression() accuracy 1.0\n",
      "nlp_encoder LogisticRegression() accuracy 1.0\n",
      "outliers LogisticRegression() accuracy 1.0\n",
      "pd_df LogisticRegression() accuracy 1.0\n",
      "ms LogisticRegression() accuracy 1.0\n",
      "models trained...\n"
     ]
    }
   ],
   "source": [
    "from mllibs.interface import interface\n",
    "\n",
    "session = interface()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63b5969d",
   "metadata": {
    "papermill": {
     "duration": 0.027237,
     "end_time": "2023-05-25T15:51:20.192001",
     "exception": false,
     "start_time": "2023-05-25T15:51:20.164764",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<div style=\"color:white;border-radius:8px;background-color:#323232;font-size:100%\">\n",
    "<p style=\"padding: 10px;color:white;\"><b><span style='color:#B6DA32; font-weight:bold'> 2.2 | LOAD DATA\n",
    "</span></b></p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "32233436",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-25T15:51:20.246514Z",
     "iopub.status.busy": "2023-05-25T15:51:20.245439Z",
     "iopub.status.idle": "2023-05-25T15:51:20.449637Z",
     "shell.execute_reply": "2023-05-25T15:51:20.448362Z"
    },
    "papermill": {
     "duration": 0.232354,
     "end_time": "2023-05-25T15:51:20.452167",
     "exception": false,
     "start_time": "2023-05-25T15:51:20.219813",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_passengers</th>\n",
       "      <th>sales_channel</th>\n",
       "      <th>trip_type</th>\n",
       "      <th>purchase_lead</th>\n",
       "      <th>length_of_stay</th>\n",
       "      <th>flight_hour</th>\n",
       "      <th>flight_day</th>\n",
       "      <th>route</th>\n",
       "      <th>booking_origin</th>\n",
       "      <th>wants_extra_baggage</th>\n",
       "      <th>wants_preferred_seat</th>\n",
       "      <th>wants_in_flight_meals</th>\n",
       "      <th>flight_duration</th>\n",
       "      <th>booking_complete</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>Internet</td>\n",
       "      <td>RoundTrip</td>\n",
       "      <td>262</td>\n",
       "      <td>19</td>\n",
       "      <td>7</td>\n",
       "      <td>Sat</td>\n",
       "      <td>AKLDEL</td>\n",
       "      <td>New Zealand</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.52</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Internet</td>\n",
       "      <td>RoundTrip</td>\n",
       "      <td>112</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>Sat</td>\n",
       "      <td>AKLDEL</td>\n",
       "      <td>New Zealand</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.52</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Internet</td>\n",
       "      <td>RoundTrip</td>\n",
       "      <td>243</td>\n",
       "      <td>22</td>\n",
       "      <td>17</td>\n",
       "      <td>Wed</td>\n",
       "      <td>AKLDEL</td>\n",
       "      <td>India</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5.52</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Internet</td>\n",
       "      <td>RoundTrip</td>\n",
       "      <td>96</td>\n",
       "      <td>31</td>\n",
       "      <td>4</td>\n",
       "      <td>Sat</td>\n",
       "      <td>AKLDEL</td>\n",
       "      <td>New Zealand</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5.52</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>Internet</td>\n",
       "      <td>RoundTrip</td>\n",
       "      <td>68</td>\n",
       "      <td>22</td>\n",
       "      <td>15</td>\n",
       "      <td>Wed</td>\n",
       "      <td>AKLDEL</td>\n",
       "      <td>India</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5.52</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>2</td>\n",
       "      <td>Internet</td>\n",
       "      <td>RoundTrip</td>\n",
       "      <td>27</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>Sat</td>\n",
       "      <td>PERPNH</td>\n",
       "      <td>Australia</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>1</td>\n",
       "      <td>Internet</td>\n",
       "      <td>RoundTrip</td>\n",
       "      <td>111</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>Sun</td>\n",
       "      <td>PERPNH</td>\n",
       "      <td>Australia</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>1</td>\n",
       "      <td>Internet</td>\n",
       "      <td>RoundTrip</td>\n",
       "      <td>24</td>\n",
       "      <td>6</td>\n",
       "      <td>22</td>\n",
       "      <td>Sat</td>\n",
       "      <td>PERPNH</td>\n",
       "      <td>Australia</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>1</td>\n",
       "      <td>Internet</td>\n",
       "      <td>RoundTrip</td>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>Mon</td>\n",
       "      <td>PERPNH</td>\n",
       "      <td>Australia</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>1</td>\n",
       "      <td>Internet</td>\n",
       "      <td>RoundTrip</td>\n",
       "      <td>19</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>Thu</td>\n",
       "      <td>PERPNH</td>\n",
       "      <td>Australia</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       num_passengers sales_channel  trip_type  purchase_lead  length_of_stay  \\\n",
       "0                   2      Internet  RoundTrip            262              19   \n",
       "1                   1      Internet  RoundTrip            112              20   \n",
       "2                   2      Internet  RoundTrip            243              22   \n",
       "3                   1      Internet  RoundTrip             96              31   \n",
       "4                   2      Internet  RoundTrip             68              22   \n",
       "...               ...           ...        ...            ...             ...   \n",
       "49995               2      Internet  RoundTrip             27               6   \n",
       "49996               1      Internet  RoundTrip            111               6   \n",
       "49997               1      Internet  RoundTrip             24               6   \n",
       "49998               1      Internet  RoundTrip             15               6   \n",
       "49999               1      Internet  RoundTrip             19               6   \n",
       "\n",
       "       flight_hour flight_day   route booking_origin  wants_extra_baggage  \\\n",
       "0                7        Sat  AKLDEL    New Zealand                    1   \n",
       "1                3        Sat  AKLDEL    New Zealand                    0   \n",
       "2               17        Wed  AKLDEL          India                    1   \n",
       "3                4        Sat  AKLDEL    New Zealand                    0   \n",
       "4               15        Wed  AKLDEL          India                    1   \n",
       "...            ...        ...     ...            ...                  ...   \n",
       "49995            9        Sat  PERPNH      Australia                    1   \n",
       "49996            4        Sun  PERPNH      Australia                    0   \n",
       "49997           22        Sat  PERPNH      Australia                    0   \n",
       "49998           11        Mon  PERPNH      Australia                    1   \n",
       "49999           10        Thu  PERPNH      Australia                    0   \n",
       "\n",
       "       wants_preferred_seat  wants_in_flight_meals  flight_duration  \\\n",
       "0                         0                      0             5.52   \n",
       "1                         0                      0             5.52   \n",
       "2                         1                      0             5.52   \n",
       "3                         0                      1             5.52   \n",
       "4                         0                      1             5.52   \n",
       "...                     ...                    ...              ...   \n",
       "49995                     0                      1             5.62   \n",
       "49996                     0                      0             5.62   \n",
       "49997                     0                      1             5.62   \n",
       "49998                     0                      1             5.62   \n",
       "49999                     1                      0             5.62   \n",
       "\n",
       "       booking_complete  \n",
       "0                     0  \n",
       "1                     0  \n",
       "2                     0  \n",
       "3                     0  \n",
       "4                     0  \n",
       "...                 ...  \n",
       "49995                 0  \n",
       "49996                 0  \n",
       "49997                 0  \n",
       "49998                 0  \n",
       "49999                 0  \n",
       "\n",
       "[50000 rows x 14 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "booking = pd.read_csv('/kaggle/input/british-airways-virtual-experience-programme/customer_booking.csv',encoding=\"ISO-8859-1\")\n",
    "session.store(booking,'booking')\n",
    "booking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec420413",
   "metadata": {
    "papermill": {
     "duration": 0.013398,
     "end_time": "2023-05-25T15:51:20.479303",
     "exception": false,
     "start_time": "2023-05-25T15:51:20.465905",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## <b><span style='color:#B6DA32'>3 | TRADITIONAL METHODS</span></b>\n",
    "\n",
    "<div style=\"color:white;border-radius:8px;background-color:#323232;font-size:100%\">\n",
    "<p style=\"padding: 10px;color:white;\"><b><span style='color:#B6DA32; font-weight:bold'> 3.1 | OHE-HOT-ENCODING\n",
    "</span></b></p>\n",
    "</div>\n",
    "\n",
    "- One-Hot Encoding is a commonly used method to convert a column of text into a present/not present column\n",
    "- By default if we pass a dataframe, it will one-hot encode all columns containing categorical like data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7bd9e523",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-25T15:51:20.508930Z",
     "iopub.status.busy": "2023-05-25T15:51:20.507747Z",
     "iopub.status.idle": "2023-05-25T15:51:20.929002Z",
     "shell.execute_reply": "2023-05-25T15:51:20.928048Z"
    },
    "papermill": {
     "duration": 0.438852,
     "end_time": "2023-05-25T15:51:20.931647",
     "exception": false,
     "start_time": "2023-05-25T15:51:20.492795",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using module: nlp_encoder\n",
      "Executing Module Task: encoding_ohe\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_passengers</th>\n",
       "      <th>purchase_lead</th>\n",
       "      <th>length_of_stay</th>\n",
       "      <th>flight_hour</th>\n",
       "      <th>wants_extra_baggage</th>\n",
       "      <th>wants_preferred_seat</th>\n",
       "      <th>wants_in_flight_meals</th>\n",
       "      <th>flight_duration</th>\n",
       "      <th>booking_complete</th>\n",
       "      <th>sales_channel_Internet</th>\n",
       "      <th>...</th>\n",
       "      <th>booking_origin_Timor-Leste</th>\n",
       "      <th>booking_origin_Tonga</th>\n",
       "      <th>booking_origin_Tunisia</th>\n",
       "      <th>booking_origin_Turkey</th>\n",
       "      <th>booking_origin_Ukraine</th>\n",
       "      <th>booking_origin_United Arab Emirates</th>\n",
       "      <th>booking_origin_United Kingdom</th>\n",
       "      <th>booking_origin_United States</th>\n",
       "      <th>booking_origin_Vanuatu</th>\n",
       "      <th>booking_origin_Vietnam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>262</td>\n",
       "      <td>19</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.52</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>112</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.52</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>243</td>\n",
       "      <td>22</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5.52</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>96</td>\n",
       "      <td>31</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5.52</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>68</td>\n",
       "      <td>22</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5.52</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>2</td>\n",
       "      <td>27</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5.62</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>1</td>\n",
       "      <td>111</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.62</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>6</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5.62</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5.62</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5.62</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows × 924 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       num_passengers  purchase_lead  length_of_stay  flight_hour  \\\n",
       "0                   2            262              19            7   \n",
       "1                   1            112              20            3   \n",
       "2                   2            243              22           17   \n",
       "3                   1             96              31            4   \n",
       "4                   2             68              22           15   \n",
       "...               ...            ...             ...          ...   \n",
       "49995               2             27               6            9   \n",
       "49996               1            111               6            4   \n",
       "49997               1             24               6           22   \n",
       "49998               1             15               6           11   \n",
       "49999               1             19               6           10   \n",
       "\n",
       "       wants_extra_baggage  wants_preferred_seat  wants_in_flight_meals  \\\n",
       "0                        1                     0                      0   \n",
       "1                        0                     0                      0   \n",
       "2                        1                     1                      0   \n",
       "3                        0                     0                      1   \n",
       "4                        1                     0                      1   \n",
       "...                    ...                   ...                    ...   \n",
       "49995                    1                     0                      1   \n",
       "49996                    0                     0                      0   \n",
       "49997                    0                     0                      1   \n",
       "49998                    1                     0                      1   \n",
       "49999                    0                     1                      0   \n",
       "\n",
       "       flight_duration  booking_complete  sales_channel_Internet  ...  \\\n",
       "0                 5.52                 0                       1  ...   \n",
       "1                 5.52                 0                       1  ...   \n",
       "2                 5.52                 0                       1  ...   \n",
       "3                 5.52                 0                       1  ...   \n",
       "4                 5.52                 0                       1  ...   \n",
       "...                ...               ...                     ...  ...   \n",
       "49995             5.62                 0                       1  ...   \n",
       "49996             5.62                 0                       1  ...   \n",
       "49997             5.62                 0                       1  ...   \n",
       "49998             5.62                 0                       1  ...   \n",
       "49999             5.62                 0                       1  ...   \n",
       "\n",
       "       booking_origin_Timor-Leste  booking_origin_Tonga  \\\n",
       "0                               0                     0   \n",
       "1                               0                     0   \n",
       "2                               0                     0   \n",
       "3                               0                     0   \n",
       "4                               0                     0   \n",
       "...                           ...                   ...   \n",
       "49995                           0                     0   \n",
       "49996                           0                     0   \n",
       "49997                           0                     0   \n",
       "49998                           0                     0   \n",
       "49999                           0                     0   \n",
       "\n",
       "       booking_origin_Tunisia  booking_origin_Turkey  booking_origin_Ukraine  \\\n",
       "0                           0                      0                       0   \n",
       "1                           0                      0                       0   \n",
       "2                           0                      0                       0   \n",
       "3                           0                      0                       0   \n",
       "4                           0                      0                       0   \n",
       "...                       ...                    ...                     ...   \n",
       "49995                       0                      0                       0   \n",
       "49996                       0                      0                       0   \n",
       "49997                       0                      0                       0   \n",
       "49998                       0                      0                       0   \n",
       "49999                       0                      0                       0   \n",
       "\n",
       "       booking_origin_United Arab Emirates  booking_origin_United Kingdom  \\\n",
       "0                                        0                              0   \n",
       "1                                        0                              0   \n",
       "2                                        0                              0   \n",
       "3                                        0                              0   \n",
       "4                                        0                              0   \n",
       "...                                    ...                            ...   \n",
       "49995                                    0                              0   \n",
       "49996                                    0                              0   \n",
       "49997                                    0                              0   \n",
       "49998                                    0                              0   \n",
       "49999                                    0                              0   \n",
       "\n",
       "       booking_origin_United States  booking_origin_Vanuatu  \\\n",
       "0                                 0                       0   \n",
       "1                                 0                       0   \n",
       "2                                 0                       0   \n",
       "3                                 0                       0   \n",
       "4                                 0                       0   \n",
       "...                             ...                     ...   \n",
       "49995                             0                       0   \n",
       "49996                             0                       0   \n",
       "49997                             0                       0   \n",
       "49998                             0                       0   \n",
       "49999                             0                       0   \n",
       "\n",
       "       booking_origin_Vietnam  \n",
       "0                           0  \n",
       "1                           0  \n",
       "2                           0  \n",
       "3                           0  \n",
       "4                           0  \n",
       "...                       ...  \n",
       "49995                       0  \n",
       "49996                       0  \n",
       "49997                       0  \n",
       "49998                       0  \n",
       "49999                       0  \n",
       "\n",
       "[50000 rows x 924 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.exec('one hot encode of booking')\n",
    "session.glr()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6d3cef9",
   "metadata": {
    "papermill": {
     "duration": 0.013917,
     "end_time": "2023-05-25T15:51:20.960075",
     "exception": false,
     "start_time": "2023-05-25T15:51:20.946158",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "- Or we can specify a specific column, returning the dataframe with the updated columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd8115c5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-25T15:51:20.991002Z",
     "iopub.status.busy": "2023-05-25T15:51:20.990516Z",
     "iopub.status.idle": "2023-05-25T15:51:21.067239Z",
     "shell.execute_reply": "2023-05-25T15:51:21.066031Z"
    },
    "papermill": {
     "duration": 0.095962,
     "end_time": "2023-05-25T15:51:21.070365",
     "exception": false,
     "start_time": "2023-05-25T15:51:20.974403",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using module: nlp_encoder\n",
      "Executing Module Task: encoding_ohe\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_passengers</th>\n",
       "      <th>sales_channel</th>\n",
       "      <th>purchase_lead</th>\n",
       "      <th>length_of_stay</th>\n",
       "      <th>flight_hour</th>\n",
       "      <th>flight_day</th>\n",
       "      <th>route</th>\n",
       "      <th>booking_origin</th>\n",
       "      <th>wants_extra_baggage</th>\n",
       "      <th>wants_preferred_seat</th>\n",
       "      <th>wants_in_flight_meals</th>\n",
       "      <th>flight_duration</th>\n",
       "      <th>booking_complete</th>\n",
       "      <th>trip_type_CircleTrip</th>\n",
       "      <th>trip_type_OneWay</th>\n",
       "      <th>trip_type_RoundTrip</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>Internet</td>\n",
       "      <td>262</td>\n",
       "      <td>19</td>\n",
       "      <td>7</td>\n",
       "      <td>Sat</td>\n",
       "      <td>AKLDEL</td>\n",
       "      <td>New Zealand</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.52</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Internet</td>\n",
       "      <td>112</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>Sat</td>\n",
       "      <td>AKLDEL</td>\n",
       "      <td>New Zealand</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.52</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Internet</td>\n",
       "      <td>243</td>\n",
       "      <td>22</td>\n",
       "      <td>17</td>\n",
       "      <td>Wed</td>\n",
       "      <td>AKLDEL</td>\n",
       "      <td>India</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5.52</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Internet</td>\n",
       "      <td>96</td>\n",
       "      <td>31</td>\n",
       "      <td>4</td>\n",
       "      <td>Sat</td>\n",
       "      <td>AKLDEL</td>\n",
       "      <td>New Zealand</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5.52</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>Internet</td>\n",
       "      <td>68</td>\n",
       "      <td>22</td>\n",
       "      <td>15</td>\n",
       "      <td>Wed</td>\n",
       "      <td>AKLDEL</td>\n",
       "      <td>India</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5.52</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>2</td>\n",
       "      <td>Internet</td>\n",
       "      <td>27</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>Sat</td>\n",
       "      <td>PERPNH</td>\n",
       "      <td>Australia</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5.62</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>1</td>\n",
       "      <td>Internet</td>\n",
       "      <td>111</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>Sun</td>\n",
       "      <td>PERPNH</td>\n",
       "      <td>Australia</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.62</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>1</td>\n",
       "      <td>Internet</td>\n",
       "      <td>24</td>\n",
       "      <td>6</td>\n",
       "      <td>22</td>\n",
       "      <td>Sat</td>\n",
       "      <td>PERPNH</td>\n",
       "      <td>Australia</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5.62</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>1</td>\n",
       "      <td>Internet</td>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>Mon</td>\n",
       "      <td>PERPNH</td>\n",
       "      <td>Australia</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5.62</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>1</td>\n",
       "      <td>Internet</td>\n",
       "      <td>19</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>Thu</td>\n",
       "      <td>PERPNH</td>\n",
       "      <td>Australia</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5.62</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       num_passengers sales_channel  purchase_lead  length_of_stay  \\\n",
       "0                   2      Internet            262              19   \n",
       "1                   1      Internet            112              20   \n",
       "2                   2      Internet            243              22   \n",
       "3                   1      Internet             96              31   \n",
       "4                   2      Internet             68              22   \n",
       "...               ...           ...            ...             ...   \n",
       "49995               2      Internet             27               6   \n",
       "49996               1      Internet            111               6   \n",
       "49997               1      Internet             24               6   \n",
       "49998               1      Internet             15               6   \n",
       "49999               1      Internet             19               6   \n",
       "\n",
       "       flight_hour flight_day   route booking_origin  wants_extra_baggage  \\\n",
       "0                7        Sat  AKLDEL    New Zealand                    1   \n",
       "1                3        Sat  AKLDEL    New Zealand                    0   \n",
       "2               17        Wed  AKLDEL          India                    1   \n",
       "3                4        Sat  AKLDEL    New Zealand                    0   \n",
       "4               15        Wed  AKLDEL          India                    1   \n",
       "...            ...        ...     ...            ...                  ...   \n",
       "49995            9        Sat  PERPNH      Australia                    1   \n",
       "49996            4        Sun  PERPNH      Australia                    0   \n",
       "49997           22        Sat  PERPNH      Australia                    0   \n",
       "49998           11        Mon  PERPNH      Australia                    1   \n",
       "49999           10        Thu  PERPNH      Australia                    0   \n",
       "\n",
       "       wants_preferred_seat  wants_in_flight_meals  flight_duration  \\\n",
       "0                         0                      0             5.52   \n",
       "1                         0                      0             5.52   \n",
       "2                         1                      0             5.52   \n",
       "3                         0                      1             5.52   \n",
       "4                         0                      1             5.52   \n",
       "...                     ...                    ...              ...   \n",
       "49995                     0                      1             5.62   \n",
       "49996                     0                      0             5.62   \n",
       "49997                     0                      1             5.62   \n",
       "49998                     0                      1             5.62   \n",
       "49999                     1                      0             5.62   \n",
       "\n",
       "       booking_complete  trip_type_CircleTrip  trip_type_OneWay  \\\n",
       "0                     0                     0                 0   \n",
       "1                     0                     0                 0   \n",
       "2                     0                     0                 0   \n",
       "3                     0                     0                 0   \n",
       "4                     0                     0                 0   \n",
       "...                 ...                   ...               ...   \n",
       "49995                 0                     0                 0   \n",
       "49996                 0                     0                 0   \n",
       "49997                 0                     0                 0   \n",
       "49998                 0                     0                 0   \n",
       "49999                 0                     0                 0   \n",
       "\n",
       "       trip_type_RoundTrip  \n",
       "0                        1  \n",
       "1                        1  \n",
       "2                        1  \n",
       "3                        1  \n",
       "4                        1  \n",
       "...                    ...  \n",
       "49995                    1  \n",
       "49996                    1  \n",
       "49997                    1  \n",
       "49998                    1  \n",
       "49999                    1  \n",
       "\n",
       "[50000 rows x 16 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.exec('one hot encode of booking trip_type')\n",
    "session.glr()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a177817b",
   "metadata": {
    "papermill": {
     "duration": 0.01494,
     "end_time": "2023-05-25T15:51:21.100737",
     "exception": false,
     "start_time": "2023-05-25T15:51:21.085797",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<div style=\"color:white;border-radius:8px;background-color:#323232;font-size:100%\">\n",
    "<p style=\"padding: 10px;color:white;\"><b><span style='color:#B6DA32; font-weight:bold'> 3.2 | LABEL ENCODING\n",
    "</span></b></p>\n",
    "</div>\n",
    "\n",
    "- **Label encoding** is mainly used for **mapping labels** (target variable) from categorical data to numeric\n",
    "- Unlike ordinal mapping (to control value order), the values are assigned based on a mapping dictionary in the order in which the key tokens were generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7d94de34",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-25T15:51:21.133584Z",
     "iopub.status.busy": "2023-05-25T15:51:21.133155Z",
     "iopub.status.idle": "2023-05-25T15:51:21.194240Z",
     "shell.execute_reply": "2023-05-25T15:51:21.193042Z"
    },
    "papermill": {
     "duration": 0.080753,
     "end_time": "2023-05-25T15:51:21.197125",
     "exception": false,
     "start_time": "2023-05-25T15:51:21.116372",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using module: nlp_encoder\n",
      "Executing Module Task: encoding_label\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sales_channel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       sales_channel\n",
       "0                  0\n",
       "1                  0\n",
       "2                  0\n",
       "3                  0\n",
       "4                  0\n",
       "...              ...\n",
       "49995              0\n",
       "49996              0\n",
       "49997              0\n",
       "49998              0\n",
       "49999              0\n",
       "\n",
       "[50000 rows x 1 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "booking_subset = booking[['sales_channel']]\n",
    "session.store(booking_subset,'subset_column')\n",
    "session['label encode subset_column']\n",
    "session.glr()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f30965a5",
   "metadata": {
    "papermill": {
     "duration": 0.015619,
     "end_time": "2023-05-25T15:51:21.228603",
     "exception": false,
     "start_time": "2023-05-25T15:51:21.212984",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Its more convenient to specify a dataframe a columnm which will return an updated dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7e003c63",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-25T15:51:21.263110Z",
     "iopub.status.busy": "2023-05-25T15:51:21.262653Z",
     "iopub.status.idle": "2023-05-25T15:51:21.352437Z",
     "shell.execute_reply": "2023-05-25T15:51:21.351034Z"
    },
    "papermill": {
     "duration": 0.110686,
     "end_time": "2023-05-25T15:51:21.354999",
     "exception": false,
     "start_time": "2023-05-25T15:51:21.244313",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using module: nlp_encoder\n",
      "Executing Module Task: encoding_label\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_passengers</th>\n",
       "      <th>trip_type</th>\n",
       "      <th>purchase_lead</th>\n",
       "      <th>length_of_stay</th>\n",
       "      <th>flight_hour</th>\n",
       "      <th>flight_day</th>\n",
       "      <th>route</th>\n",
       "      <th>booking_origin</th>\n",
       "      <th>wants_extra_baggage</th>\n",
       "      <th>wants_preferred_seat</th>\n",
       "      <th>wants_in_flight_meals</th>\n",
       "      <th>flight_duration</th>\n",
       "      <th>booking_complete</th>\n",
       "      <th>sales_channel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>RoundTrip</td>\n",
       "      <td>262</td>\n",
       "      <td>19</td>\n",
       "      <td>7</td>\n",
       "      <td>Sat</td>\n",
       "      <td>AKLDEL</td>\n",
       "      <td>New Zealand</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.52</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>RoundTrip</td>\n",
       "      <td>112</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>Sat</td>\n",
       "      <td>AKLDEL</td>\n",
       "      <td>New Zealand</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.52</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>RoundTrip</td>\n",
       "      <td>243</td>\n",
       "      <td>22</td>\n",
       "      <td>17</td>\n",
       "      <td>Wed</td>\n",
       "      <td>AKLDEL</td>\n",
       "      <td>India</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5.52</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>RoundTrip</td>\n",
       "      <td>96</td>\n",
       "      <td>31</td>\n",
       "      <td>4</td>\n",
       "      <td>Sat</td>\n",
       "      <td>AKLDEL</td>\n",
       "      <td>New Zealand</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5.52</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>RoundTrip</td>\n",
       "      <td>68</td>\n",
       "      <td>22</td>\n",
       "      <td>15</td>\n",
       "      <td>Wed</td>\n",
       "      <td>AKLDEL</td>\n",
       "      <td>India</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5.52</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>2</td>\n",
       "      <td>RoundTrip</td>\n",
       "      <td>27</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>Sat</td>\n",
       "      <td>PERPNH</td>\n",
       "      <td>Australia</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5.62</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>1</td>\n",
       "      <td>RoundTrip</td>\n",
       "      <td>111</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>Sun</td>\n",
       "      <td>PERPNH</td>\n",
       "      <td>Australia</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.62</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>1</td>\n",
       "      <td>RoundTrip</td>\n",
       "      <td>24</td>\n",
       "      <td>6</td>\n",
       "      <td>22</td>\n",
       "      <td>Sat</td>\n",
       "      <td>PERPNH</td>\n",
       "      <td>Australia</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5.62</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>1</td>\n",
       "      <td>RoundTrip</td>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>Mon</td>\n",
       "      <td>PERPNH</td>\n",
       "      <td>Australia</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5.62</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>1</td>\n",
       "      <td>RoundTrip</td>\n",
       "      <td>19</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>Thu</td>\n",
       "      <td>PERPNH</td>\n",
       "      <td>Australia</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5.62</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       num_passengers  trip_type  purchase_lead  length_of_stay  flight_hour  \\\n",
       "0                   2  RoundTrip            262              19            7   \n",
       "1                   1  RoundTrip            112              20            3   \n",
       "2                   2  RoundTrip            243              22           17   \n",
       "3                   1  RoundTrip             96              31            4   \n",
       "4                   2  RoundTrip             68              22           15   \n",
       "...               ...        ...            ...             ...          ...   \n",
       "49995               2  RoundTrip             27               6            9   \n",
       "49996               1  RoundTrip            111               6            4   \n",
       "49997               1  RoundTrip             24               6           22   \n",
       "49998               1  RoundTrip             15               6           11   \n",
       "49999               1  RoundTrip             19               6           10   \n",
       "\n",
       "      flight_day   route booking_origin  wants_extra_baggage  \\\n",
       "0            Sat  AKLDEL    New Zealand                    1   \n",
       "1            Sat  AKLDEL    New Zealand                    0   \n",
       "2            Wed  AKLDEL          India                    1   \n",
       "3            Sat  AKLDEL    New Zealand                    0   \n",
       "4            Wed  AKLDEL          India                    1   \n",
       "...          ...     ...            ...                  ...   \n",
       "49995        Sat  PERPNH      Australia                    1   \n",
       "49996        Sun  PERPNH      Australia                    0   \n",
       "49997        Sat  PERPNH      Australia                    0   \n",
       "49998        Mon  PERPNH      Australia                    1   \n",
       "49999        Thu  PERPNH      Australia                    0   \n",
       "\n",
       "       wants_preferred_seat  wants_in_flight_meals  flight_duration  \\\n",
       "0                         0                      0             5.52   \n",
       "1                         0                      0             5.52   \n",
       "2                         1                      0             5.52   \n",
       "3                         0                      1             5.52   \n",
       "4                         0                      1             5.52   \n",
       "...                     ...                    ...              ...   \n",
       "49995                     0                      1             5.62   \n",
       "49996                     0                      0             5.62   \n",
       "49997                     0                      1             5.62   \n",
       "49998                     0                      1             5.62   \n",
       "49999                     1                      0             5.62   \n",
       "\n",
       "       booking_complete  sales_channel  \n",
       "0                     0              0  \n",
       "1                     0              0  \n",
       "2                     0              0  \n",
       "3                     0              0  \n",
       "4                     0              0  \n",
       "...                 ...            ...  \n",
       "49995                 0              0  \n",
       "49996                 0              0  \n",
       "49997                 0              0  \n",
       "49998                 0              0  \n",
       "49999                 0              0  \n",
       "\n",
       "[50000 rows x 14 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.exec('label encode booking sales_channel')\n",
    "session.glr()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0debdc9d",
   "metadata": {
    "papermill": {
     "duration": 0.016194,
     "end_time": "2023-05-25T15:51:21.387596",
     "exception": false,
     "start_time": "2023-05-25T15:51:21.371402",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<div style=\"color:white;border-radius:8px;background-color:#323232;font-size:100%\">\n",
    "<p style=\"padding: 10px;color:white;\"><b><span style='color:#B6DA32; font-weight:bold'> 3.3 | COUNT VECTORISER\n",
    "</span></b></p>\n",
    "</div>\n",
    "\n",
    "#### <b><span style='color:#CAE68D'>ADJUSTING FREQUENCY LIMITS</span></b>\n",
    "\n",
    "As per usual, lets store the data we will use "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a3ff3898",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-25T15:51:21.422193Z",
     "iopub.status.busy": "2023-05-25T15:51:21.421731Z",
     "iopub.status.idle": "2023-05-25T15:51:21.428787Z",
     "shell.execute_reply": "2023-05-25T15:51:21.427580Z"
    },
    "papermill": {
     "duration": 0.027189,
     "end_time": "2023-05-25T15:51:21.431097",
     "exception": false,
     "start_time": "2023-05-25T15:51:21.403908",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "doc_sample = ['This is the first document, this is the start.',\n",
    "              'Following the first is the second setence',\n",
    "              'And then comes the third document, this is the ending']\n",
    "\n",
    "df_doc_sample = pd.Series(doc_sample).to_frame()\n",
    "df_doc_sample.columns = ['corpus']\n",
    "session.store(df_doc_sample,'corpus_data')\n",
    "session.store(doc_sample,'corpus_list')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c45d0280",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-25T15:51:21.465850Z",
     "iopub.status.busy": "2023-05-25T15:51:21.465115Z",
     "iopub.status.idle": "2023-05-25T15:51:21.497530Z",
     "shell.execute_reply": "2023-05-25T15:51:21.496521Z"
    },
    "papermill": {
     "duration": 0.052379,
     "end_time": "2023-05-25T15:51:21.499686",
     "exception": false,
     "start_time": "2023-05-25T15:51:21.447307",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using module: nlp_encoder\n",
      "Executing Module Task: count_vectoriser\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>and</th>\n",
       "      <th>comes</th>\n",
       "      <th>ending</th>\n",
       "      <th>following</th>\n",
       "      <th>second</th>\n",
       "      <th>setence</th>\n",
       "      <th>start</th>\n",
       "      <th>then</th>\n",
       "      <th>third</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   and  comes  ending  following  second  setence  start  then  third\n",
       "0    0      0       0          0       0        0      1     0      0\n",
       "1    0      0       0          1       1        1      0     0      0\n",
       "2    1      1       1          0       0        0      0     1      1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.exec('count vectorise corpus_data corpus')\n",
    "session.glr()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25423a0b",
   "metadata": {
    "papermill": {
     "duration": 0.016003,
     "end_time": "2023-05-25T15:51:21.532129",
     "exception": false,
     "start_time": "2023-05-25T15:51:21.516126",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### <b><span style='color:#CAE68D'>ADJUSTING FREQUENCY LIMITS</span></b>\n",
    "\n",
    "We can adjust the token encounter frquencies <code>min_df</code>, <code>max_df</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cf9f5f0d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-25T15:51:21.567384Z",
     "iopub.status.busy": "2023-05-25T15:51:21.566433Z",
     "iopub.status.idle": "2023-05-25T15:51:21.600238Z",
     "shell.execute_reply": "2023-05-25T15:51:21.599044Z"
    },
    "papermill": {
     "duration": 0.054063,
     "end_time": "2023-05-25T15:51:21.602658",
     "exception": false,
     "start_time": "2023-05-25T15:51:21.548595",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using module: nlp_encoder\n",
      "Executing Module Task: count_vectoriser\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>and</th>\n",
       "      <th>comes</th>\n",
       "      <th>document</th>\n",
       "      <th>ending</th>\n",
       "      <th>first</th>\n",
       "      <th>following</th>\n",
       "      <th>second</th>\n",
       "      <th>setence</th>\n",
       "      <th>start</th>\n",
       "      <th>then</th>\n",
       "      <th>third</th>\n",
       "      <th>this</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   and  comes  document  ending  first  following  second  setence  start  \\\n",
       "0    0      0         1       0      1          0       0        0      1   \n",
       "1    0      0         0       0      1          1       1        1      0   \n",
       "2    1      1         1       1      0          0       0        0      0   \n",
       "\n",
       "   then  third  this  \n",
       "0     0      0     2  \n",
       "1     0      0     0  \n",
       "2     1      1     1  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.exec('count vectorise corpus_data max_df 2')\n",
    "session.glr()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a9b206b",
   "metadata": {
    "papermill": {
     "duration": 0.01652,
     "end_time": "2023-05-25T15:51:21.636135",
     "exception": false,
     "start_time": "2023-05-25T15:51:21.619615",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### <b><span style='color:#CAE68D'>NGRAM RANGE</span></b>\n",
    "\n",
    "We can also adjust the ngram range using token <code>ngram_range</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "77dea99d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-25T15:51:21.672462Z",
     "iopub.status.busy": "2023-05-25T15:51:21.671763Z",
     "iopub.status.idle": "2023-05-25T15:51:21.711549Z",
     "shell.execute_reply": "2023-05-25T15:51:21.710383Z"
    },
    "papermill": {
     "duration": 0.060688,
     "end_time": "2023-05-25T15:51:21.714103",
     "exception": false,
     "start_time": "2023-05-25T15:51:21.653415",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using module: nlp_encoder\n",
      "Executing Module Task: count_vectoriser\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>and</th>\n",
       "      <th>and then</th>\n",
       "      <th>comes</th>\n",
       "      <th>comes the</th>\n",
       "      <th>ending</th>\n",
       "      <th>first document</th>\n",
       "      <th>first is</th>\n",
       "      <th>following</th>\n",
       "      <th>following the</th>\n",
       "      <th>second</th>\n",
       "      <th>...</th>\n",
       "      <th>setence</th>\n",
       "      <th>start</th>\n",
       "      <th>the ending</th>\n",
       "      <th>the second</th>\n",
       "      <th>the start</th>\n",
       "      <th>the third</th>\n",
       "      <th>then</th>\n",
       "      <th>then comes</th>\n",
       "      <th>third</th>\n",
       "      <th>third document</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   and  and then  comes  comes the  ending  first document  first is  \\\n",
       "0    0         0      0          0       0               1         0   \n",
       "1    0         0      0          0       0               0         1   \n",
       "2    1         1      1          1       1               0         0   \n",
       "\n",
       "   following  following the  second  ...  setence  start  the ending  \\\n",
       "0          0              0       0  ...        0      1           0   \n",
       "1          1              1       1  ...        1      0           0   \n",
       "2          0              0       0  ...        0      0           1   \n",
       "\n",
       "   the second  the start  the third  then  then comes  third  third document  \n",
       "0           0          1          0     0           0      0               0  \n",
       "1           1          0          0     0           0      0               0  \n",
       "2           0          0          1     1           1      1               1  \n",
       "\n",
       "[3 rows x 21 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.exec('count vectorise corpus_data ngram_range (1,2)')\n",
    "session.glr()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa672b5f",
   "metadata": {
    "papermill": {
     "duration": 0.017322,
     "end_time": "2023-05-25T15:51:21.748854",
     "exception": false,
     "start_time": "2023-05-25T15:51:21.731532",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### <b><span style='color:#CAE68D'>CUSTOM TOKENISER</span></b>\n",
    "\n",
    "- We may want to utilise a customised tokeniser, by default the split pattern is <code>\\b\\w\\w+\\b</code>\n",
    "- The default tokeniser removes all special characters, punctuation and single characters.\n",
    "- **Customised tokeniser** functions allow us to preprocess the data; eg. **tokenise** and **lemmatise**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c4585901",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-25T15:51:21.786069Z",
     "iopub.status.busy": "2023-05-25T15:51:21.785617Z",
     "iopub.status.idle": "2023-05-25T15:51:21.792555Z",
     "shell.execute_reply": "2023-05-25T15:51:21.791406Z"
    },
    "papermill": {
     "duration": 0.028408,
     "end_time": "2023-05-25T15:51:21.794903",
     "exception": false,
     "start_time": "2023-05-25T15:51:21.766495",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer as wnl\n",
    "from nltk.tokenize import word_tokenize, WhitespaceTokenizer\n",
    "\n",
    "# create custom tokeniser\n",
    "def nltk_tokeniser(text):\n",
    "    tokens = WhitespaceTokenizer().tokenize(text)\n",
    "    lemmatised_tokens = [wnl().lemmatize(words) for words in tokens]\n",
    "    return lemmatised_tokens\n",
    "\n",
    "# store custom tokeniser\n",
    "tokenise = nltk_tokeniser\n",
    "session.store(nltk_tokeniser,'ws_tokeniser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "249b3b22",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-25T15:51:21.831919Z",
     "iopub.status.busy": "2023-05-25T15:51:21.831468Z",
     "iopub.status.idle": "2023-05-25T15:51:24.382443Z",
     "shell.execute_reply": "2023-05-25T15:51:24.381512Z"
    },
    "papermill": {
     "duration": 2.572385,
     "end_time": "2023-05-25T15:51:24.384852",
     "exception": false,
     "start_time": "2023-05-25T15:51:21.812467",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using module: nlp_encoder\n",
      "Executing Module Task: count_vectoriser\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>and</th>\n",
       "      <th>come</th>\n",
       "      <th>ending</th>\n",
       "      <th>following</th>\n",
       "      <th>second</th>\n",
       "      <th>setence</th>\n",
       "      <th>start.</th>\n",
       "      <th>then</th>\n",
       "      <th>third</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   and  come  ending  following  second  setence  start.  then  third\n",
       "0    0     0       0          0       0        0       1     0      0\n",
       "1    0     0       0          1       1        1       0     0      0\n",
       "2    1     1       1          0       0        0       0     1      1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.exec('count vectorise corpus_data tokeniser ws_tokeniser')\n",
    "session.glr()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4f71ea3",
   "metadata": {
    "papermill": {
     "duration": 0.017622,
     "end_time": "2023-05-25T15:51:24.420140",
     "exception": false,
     "start_time": "2023-05-25T15:51:24.402518",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<div style=\"color:white;border-radius:8px;background-color:#323232;font-size:100%\">\n",
    "<p style=\"padding: 10px;color:white;\"><b><span style='color:#B6DA32; font-weight:bold'> 3.4 | TFIDF VECTORISER\n",
    "</span></b></p>\n",
    "</div>\n",
    "\n",
    "#### <b><span style='color:#CAE68D'>WEIGHTING WORD CONTRIBUTION</span></b>\n",
    "\n",
    "- If we want a bag of words, but with **words weighted by their importance** to an observation; utilise **TF-IDF**\n",
    "- We want to compare the **frequency of the word** in a document with the **frequency of the word in all other documents** using term frequency-inverse document frequency (tf-idf)\n",
    "- **TF-IDF** work with all of the above options in addition to `use_idf` and `smooth_idf` token options\n",
    "\n",
    "#### <b><span style='color:#CAE68D'>TERMINOLOGY</span></b>\n",
    "\n",
    "- Term frequency (tf) - The more a **word appears in a document**, the more likely it is to be important to that document\n",
    "- Document frequency (df) - if a word appears in many documents, it is likely less important to any individual document\n",
    "- Combining these two statistics, we can assign a score to every word representing how important that word is in a document\n",
    "- The higher the resulting value, the more important the word is to a document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f8855a23",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2023-05-25T15:51:24.457255Z",
     "iopub.status.busy": "2023-05-25T15:51:24.456809Z",
     "iopub.status.idle": "2023-05-25T15:51:24.464072Z",
     "shell.execute_reply": "2023-05-25T15:51:24.462857Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.029004,
     "end_time": "2023-05-25T15:51:24.466831",
     "exception": false,
     "start_time": "2023-05-25T15:51:24.437827",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "list_corpus = [\n",
    "    'Girl likes cat Tom',\n",
    "    'Who likes the cat?',\n",
    "    'Tom is a quiet cat'\n",
    "]\n",
    "df_corpus = pd.Series(list_corpus).to_frame()\n",
    "df_corpus.columns = ['corpus']\n",
    "session.store(df_corpus,'ex_corpus')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bec64346",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-25T15:51:24.503922Z",
     "iopub.status.busy": "2023-05-25T15:51:24.503482Z",
     "iopub.status.idle": "2023-05-25T15:51:24.545688Z",
     "shell.execute_reply": "2023-05-25T15:51:24.544380Z"
    },
    "papermill": {
     "duration": 0.063644,
     "end_time": "2023-05-25T15:51:24.548116",
     "exception": false,
     "start_time": "2023-05-25T15:51:24.484472",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using module: nlp_encoder\n",
      "Executing Module Task: tfidf_vectoriser\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>girl</th>\n",
       "      <th>is</th>\n",
       "      <th>quiet</th>\n",
       "      <th>the</th>\n",
       "      <th>who</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.707107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   girl        is     quiet       the       who\n",
       "0   1.0  0.000000  0.000000  0.000000  0.000000\n",
       "1   0.0  0.000000  0.000000  0.707107  0.707107\n",
       "2   0.0  0.707107  0.707107  0.000000  0.000000"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.exec('tfidf dataframe ex_corpus')\n",
    "session.glr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f2252593",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-25T15:51:24.586359Z",
     "iopub.status.busy": "2023-05-25T15:51:24.585902Z",
     "iopub.status.idle": "2023-05-25T15:51:24.622796Z",
     "shell.execute_reply": "2023-05-25T15:51:24.621538Z"
    },
    "papermill": {
     "duration": 0.059193,
     "end_time": "2023-05-25T15:51:24.625387",
     "exception": false,
     "start_time": "2023-05-25T15:51:24.566194",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using module: nlp_encoder\n",
      "Executing Module Task: tfidf_vectoriser\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat</th>\n",
       "      <th>girl</th>\n",
       "      <th>is</th>\n",
       "      <th>likes</th>\n",
       "      <th>quiet</th>\n",
       "      <th>the</th>\n",
       "      <th>tom</th>\n",
       "      <th>who</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.373119</td>\n",
       "      <td>0.631745</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.480458</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.480458</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.345205</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.444514</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.584483</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.584483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.345205</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.584483</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.584483</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.444514</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        cat      girl        is     likes     quiet       the       tom  \\\n",
       "0  0.373119  0.631745  0.000000  0.480458  0.000000  0.000000  0.480458   \n",
       "1  0.345205  0.000000  0.000000  0.444514  0.000000  0.584483  0.000000   \n",
       "2  0.345205  0.000000  0.584483  0.000000  0.584483  0.000000  0.444514   \n",
       "\n",
       "        who  \n",
       "0  0.000000  \n",
       "1  0.584483  \n",
       "2  0.000000  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.exec('tfidf dataframe ex_corpus min_df 0.0 max_df 1.0')\n",
    "session.glr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "de844f8a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-25T15:51:24.665082Z",
     "iopub.status.busy": "2023-05-25T15:51:24.663731Z",
     "iopub.status.idle": "2023-05-25T15:51:24.702280Z",
     "shell.execute_reply": "2023-05-25T15:51:24.701009Z"
    },
    "papermill": {
     "duration": 0.061003,
     "end_time": "2023-05-25T15:51:24.704767",
     "exception": false,
     "start_time": "2023-05-25T15:51:24.643764",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using module: nlp_encoder\n",
      "Executing Module Task: tfidf_vectoriser\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat</th>\n",
       "      <th>girl</th>\n",
       "      <th>is</th>\n",
       "      <th>likes</th>\n",
       "      <th>quiet</th>\n",
       "      <th>the</th>\n",
       "      <th>tom</th>\n",
       "      <th>who</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.326950</td>\n",
       "      <td>0.686142</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.459517</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.459517</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.291313</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.409430</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.611353</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.611353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.291313</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.611353</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.611353</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.409430</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        cat      girl        is     likes     quiet       the       tom  \\\n",
       "0  0.326950  0.686142  0.000000  0.459517  0.000000  0.000000  0.459517   \n",
       "1  0.291313  0.000000  0.000000  0.409430  0.000000  0.611353  0.000000   \n",
       "2  0.291313  0.000000  0.611353  0.000000  0.611353  0.000000  0.409430   \n",
       "\n",
       "        who  \n",
       "0  0.000000  \n",
       "1  0.611353  \n",
       "2  0.000000  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.exec('tfidf dataframe ex_corpus min_df 0.0 max_df 1.0 smooth_idf False use_idf False')\n",
    "session.glr()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88e2f425",
   "metadata": {
    "papermill": {
     "duration": 0.018183,
     "end_time": "2023-05-25T15:51:24.741516",
     "exception": false,
     "start_time": "2023-05-25T15:51:24.723333",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<div style=\"color:white;border-radius:8px;background-color:#323232;font-size:100%\">\n",
    "<p style=\"padding: 10px;color:white;\"><b><span style='color:#B6DA32; font-weight:bold'> 3.5 | CORPUS TO PADDED TENSOR\n",
    "</span></b></p>\n",
    "</div>\n",
    "\n",
    "**PyTorch** is a common deep network framework, let's encode each **document** in a **corpus**\n",
    "- The first step that is made - tokenise the document \n",
    "- Like in the **labelencoder**, we create a **mapping dictionary** that will store a unique token identifier (we create our own based on the available tokens)\n",
    "- Once the mapping dictionary is created, we can convert each corresponding **token** to its **numerical value**  \n",
    "- To pass text data into a neural network, they need to be of equal length; so we need to **pad each document** that is shorter than the longest document length\n",
    "- We can also limit the **maximum length of all documents** by using token tag `maxlen`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "67a72742",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-25T15:51:24.781723Z",
     "iopub.status.busy": "2023-05-25T15:51:24.781202Z",
     "iopub.status.idle": "2023-05-25T15:51:24.789161Z",
     "shell.execute_reply": "2023-05-25T15:51:24.788035Z"
    },
    "papermill": {
     "duration": 0.030493,
     "end_time": "2023-05-25T15:51:24.791514",
     "exception": false,
     "start_time": "2023-05-25T15:51:24.761021",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This is the first document, this is the start.',\n",
       " 'Following the first is the second setence',\n",
       " 'And then comes the third document, this is the ending']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.data['corpus_list']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9998831e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-25T15:51:24.832446Z",
     "iopub.status.busy": "2023-05-25T15:51:24.832023Z",
     "iopub.status.idle": "2023-05-25T15:51:24.950702Z",
     "shell.execute_reply": "2023-05-25T15:51:24.949393Z"
    },
    "papermill": {
     "duration": 0.14241,
     "end_time": "2023-05-25T15:51:24.953312",
     "exception": false,
     "start_time": "2023-05-25T15:51:24.810902",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using module: nlp_encoder\n",
      "Executing Module Task: torch_text_encode\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[14,  5,  2, 15,  1, 13,  0,  5,  2,  8, 10],\n",
       "        [12,  2, 15,  5,  2,  3, 16,  0,  0,  0,  0],\n",
       "        [11,  6,  9,  2,  7,  1, 13,  0,  5,  2,  4]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.exec('torch encode for corpus_list')\n",
    "session.glr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5c00cb89",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-25T15:51:24.994343Z",
     "iopub.status.busy": "2023-05-25T15:51:24.993564Z",
     "iopub.status.idle": "2023-05-25T15:51:25.019506Z",
     "shell.execute_reply": "2023-05-25T15:51:25.018285Z"
    },
    "papermill": {
     "duration": 0.049534,
     "end_time": "2023-05-25T15:51:25.022054",
     "exception": false,
     "start_time": "2023-05-25T15:51:24.972520",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using module: nlp_encoder\n",
      "Executing Module Task: torch_text_encode\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[14,  5,  2, 15],\n",
       "        [12,  2, 15,  5],\n",
       "        [11,  6,  9,  2]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.exec('torch encode for corpus_list maxlen 4')\n",
    "session.glr()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75539fb9",
   "metadata": {
    "papermill": {
     "duration": 0.018901,
     "end_time": "2023-05-25T15:51:25.060237",
     "exception": false,
     "start_time": "2023-05-25T15:51:25.041336",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## <b><span style='color:#B6DA32'>4 | EMBEDDING METHODS</span></b>\n",
    "\n",
    "<div style=\"color:white;border-radius:8px;background-color:#323232;font-size:100%\">\n",
    "<p style=\"padding: 10px;color:white;\"><b><span style='color:#B6DA32; font-weight:bold'> 4.1 | INPUT DATA\n",
    "</span></b></p>\n",
    "</div>\n",
    "\n",
    "Input data for **embedding generation** is currenly a **list**, as opposed to a **DataFrame** for the encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ca6be543",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-25T15:51:25.100606Z",
     "iopub.status.busy": "2023-05-25T15:51:25.100050Z",
     "iopub.status.idle": "2023-05-25T15:51:25.106201Z",
     "shell.execute_reply": "2023-05-25T15:51:25.104810Z"
    },
    "papermill": {
     "duration": 0.02975,
     "end_time": "2023-05-25T15:51:25.109094",
     "exception": false,
     "start_time": "2023-05-25T15:51:25.079344",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "doc_sample = ['This is the first document.',\n",
    "              'Following the first is the second setence',\n",
    "              'And then comes the third.']\n",
    "\n",
    "session.store(doc_sample,'documents')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfd4f350",
   "metadata": {
    "papermill": {
     "duration": 0.019337,
     "end_time": "2023-05-25T15:51:25.147801",
     "exception": false,
     "start_time": "2023-05-25T15:51:25.128464",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<div style=\"color:white;border-radius:8px;background-color:#323232;font-size:100%\">\n",
    "<p style=\"padding: 10px;color:white;\"><b><span style='color:#B6DA32; font-weight:bold'> 4.2 | CBOW PROBLEM\n",
    "</span></b></p>\n",
    "</div>\n",
    "\n",
    "#### <b><span style='color:#CAE68D'>DEFINING THE PROBLEM</span></b>\n",
    "\n",
    "Our goal is to train a neural network model from which we can extract **embedding** & use them for feature generation  \n",
    "- Features for the **CBOW** problem are **context vectors** (context are the words around the main word, get all possible cases,storing the numerical representations in and the **target vector** is the word in the middle\n",
    "- Ie. using the surrounding words of window size, we create a model that will be predicting the word in the middle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "078a576f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-25T15:51:25.188847Z",
     "iopub.status.busy": "2023-05-25T15:51:25.188371Z",
     "iopub.status.idle": "2023-05-25T15:51:25.424712Z",
     "shell.execute_reply": "2023-05-25T15:51:25.423510Z"
    },
    "papermill": {
     "duration": 0.259143,
     "end_time": "2023-05-25T15:51:25.427010",
     "exception": false,
     "start_time": "2023-05-25T15:51:25.167867",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using module: nlp_embedding\n",
      "Executing Module Task: embed_cbow\n",
      "loss: 1.5057597160339355\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>.</th>\n",
       "      <td>0.983703</td>\n",
       "      <td>0.265589</td>\n",
       "      <td>0.003403</td>\n",
       "      <td>1.612110</td>\n",
       "      <td>-1.955167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>first</th>\n",
       "      <td>0.811165</td>\n",
       "      <td>1.103342</td>\n",
       "      <td>-0.765439</td>\n",
       "      <td>-0.163955</td>\n",
       "      <td>1.258642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>the</th>\n",
       "      <td>0.014258</td>\n",
       "      <td>-0.842525</td>\n",
       "      <td>-1.278209</td>\n",
       "      <td>0.500522</td>\n",
       "      <td>0.047542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>This</th>\n",
       "      <td>0.239167</td>\n",
       "      <td>-0.915592</td>\n",
       "      <td>-0.064000</td>\n",
       "      <td>-0.535537</td>\n",
       "      <td>1.320716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>document</th>\n",
       "      <td>-1.780742</td>\n",
       "      <td>0.619838</td>\n",
       "      <td>-1.931209</td>\n",
       "      <td>0.581017</td>\n",
       "      <td>-0.309666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is</th>\n",
       "      <td>-0.368827</td>\n",
       "      <td>1.003728</td>\n",
       "      <td>-0.044844</td>\n",
       "      <td>-2.012095</td>\n",
       "      <td>-0.925141</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0         1         2         3         4\n",
       ".         0.983703  0.265589  0.003403  1.612110 -1.955167\n",
       "first     0.811165  1.103342 -0.765439 -0.163955  1.258642\n",
       "the       0.014258 -0.842525 -1.278209  0.500522  0.047542\n",
       "This      0.239167 -0.915592 -0.064000 -0.535537  1.320716\n",
       "document -1.780742  0.619838 -1.931209  0.581017 -0.309666\n",
       "is       -0.368827  1.003728 -0.044844 -2.012095 -0.925141"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "\n",
    "Example\n",
    "\n",
    "context, target pairs\n",
    "\n",
    "(['Today', 'is', 'good', 'day'], 'a')\n",
    "(['is', 'a', 'day', 'for'], 'good')\n",
    "(['a', 'good', 'for', 'taking'], 'day')\n",
    "(['good', 'day', 'taking', 'a'], 'for')\n",
    "(['day', 'for', 'a', 'walk'], 'taking')\n",
    "\n",
    "for pytorch; context, target word tensors\n",
    "\n",
    "tensor([7, 2, 3, 6]) tensor(1)\n",
    "tensor([2, 1, 6, 0]) tensor(3)\n",
    "tensor([1, 3, 0, 5]) tensor(6)\n",
    "tensor([3, 6, 5, 1]) tensor(0)\n",
    "tensor([6, 0, 1, 4]) tensor(5)\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "session.exec('cbow embeddings using documents')\n",
    "session.glr()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8919ea3",
   "metadata": {
    "papermill": {
     "duration": 0.01931,
     "end_time": "2023-05-25T15:51:25.466057",
     "exception": false,
     "start_time": "2023-05-25T15:51:25.446747",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<div style=\"color:white;border-radius:8px;background-color:#323232;font-size:100%\">\n",
    "<p style=\"padding: 10px;color:white;\"><b><span style='color:#B6DA32; font-weight:bold'>4.3 | SKIP-GRAM PROBLEM\n",
    "</span></b></p>\n",
    "</div>\n",
    "\n",
    "#### <b><span style='color:#CAE68D'>DEFINING THE PROBLEM</span></b>\n",
    "\n",
    "\n",
    "Our goal is to train a neural network model from which we can extract **embedding** & use them for feature generation\n",
    "\n",
    "- The **SG** (skip-gram) variant takes a **target word** and tries to predict the **surrounding context words** (which is the opposite of **CBOW**)\n",
    "\n",
    "> - The \"fake\" task for skip-gram model would be, given a word, we’ll try to predict its neighboring words\n",
    "> - We’ll define a neighboring word by the window size — a hyper-parameter\n",
    "\n",
    "- We'll be using Keras, as we have a convenient function that generates **skip-gram** training data `keras.preprocessing.sequence.skipgrams`\n",
    "- The data generated using `skipgrams` will be elaborated using an example below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6fdced43",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-25T15:51:25.507585Z",
     "iopub.status.busy": "2023-05-25T15:51:25.507155Z",
     "iopub.status.idle": "2023-05-25T15:51:28.758391Z",
     "shell.execute_reply": "2023-05-25T15:51:28.757117Z"
    },
    "papermill": {
     "duration": 3.275632,
     "end_time": "2023-05-25T15:51:28.761439",
     "exception": false,
     "start_time": "2023-05-25T15:51:25.485807",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using module: nlp_embedding\n",
      "Executing Module Task: embed_sg\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>the</th>\n",
       "      <td>-0.033068</td>\n",
       "      <td>-0.013494</td>\n",
       "      <td>-0.092383</td>\n",
       "      <td>-0.141605</td>\n",
       "      <td>0.043779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is</th>\n",
       "      <td>0.105515</td>\n",
       "      <td>-0.085574</td>\n",
       "      <td>-0.163681</td>\n",
       "      <td>-0.064680</td>\n",
       "      <td>-0.146702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>first</th>\n",
       "      <td>0.073727</td>\n",
       "      <td>0.093489</td>\n",
       "      <td>-0.033672</td>\n",
       "      <td>-0.060684</td>\n",
       "      <td>0.033944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>this</th>\n",
       "      <td>0.052360</td>\n",
       "      <td>0.090712</td>\n",
       "      <td>0.018228</td>\n",
       "      <td>-0.027841</td>\n",
       "      <td>-0.017292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>document</th>\n",
       "      <td>0.033914</td>\n",
       "      <td>-0.086581</td>\n",
       "      <td>-0.067512</td>\n",
       "      <td>-0.018183</td>\n",
       "      <td>-0.088002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>following</th>\n",
       "      <td>0.073711</td>\n",
       "      <td>-0.076618</td>\n",
       "      <td>-0.050031</td>\n",
       "      <td>-0.052639</td>\n",
       "      <td>-0.013335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>second</th>\n",
       "      <td>0.055859</td>\n",
       "      <td>0.002303</td>\n",
       "      <td>0.047756</td>\n",
       "      <td>0.010930</td>\n",
       "      <td>-0.011968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>setence</th>\n",
       "      <td>-0.014511</td>\n",
       "      <td>-0.049895</td>\n",
       "      <td>-0.010955</td>\n",
       "      <td>0.044301</td>\n",
       "      <td>0.008440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>and</th>\n",
       "      <td>-0.001558</td>\n",
       "      <td>-0.010315</td>\n",
       "      <td>-0.055224</td>\n",
       "      <td>0.066658</td>\n",
       "      <td>0.073355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>then</th>\n",
       "      <td>-0.025927</td>\n",
       "      <td>0.055655</td>\n",
       "      <td>-0.032779</td>\n",
       "      <td>0.061319</td>\n",
       "      <td>-0.080005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>comes</th>\n",
       "      <td>-0.025251</td>\n",
       "      <td>-0.079828</td>\n",
       "      <td>0.007452</td>\n",
       "      <td>-0.004079</td>\n",
       "      <td>0.060270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>third</th>\n",
       "      <td>0.007130</td>\n",
       "      <td>0.020881</td>\n",
       "      <td>-0.093710</td>\n",
       "      <td>0.011215</td>\n",
       "      <td>-0.075976</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0         1         2         3         4\n",
       "the       -0.033068 -0.013494 -0.092383 -0.141605  0.043779\n",
       "is         0.105515 -0.085574 -0.163681 -0.064680 -0.146702\n",
       "first      0.073727  0.093489 -0.033672 -0.060684  0.033944\n",
       "this       0.052360  0.090712  0.018228 -0.027841 -0.017292\n",
       "document   0.033914 -0.086581 -0.067512 -0.018183 -0.088002\n",
       "following  0.073711 -0.076618 -0.050031 -0.052639 -0.013335\n",
       "second     0.055859  0.002303  0.047756  0.010930 -0.011968\n",
       "setence   -0.014511 -0.049895 -0.010955  0.044301  0.008440\n",
       "and       -0.001558 -0.010315 -0.055224  0.066658  0.073355\n",
       "then      -0.025927  0.055655 -0.032779  0.061319 -0.080005\n",
       "comes     -0.025251 -0.079828  0.007452 -0.004079  0.060270\n",
       "third      0.007130  0.020881 -0.093710  0.011215 -0.075976"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.exec('sg embeddings using documents')\n",
    "session.glr()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dfdd345",
   "metadata": {
    "papermill": {
     "duration": 0.019694,
     "end_time": "2023-05-25T15:51:28.801465",
     "exception": false,
     "start_time": "2023-05-25T15:51:28.781771",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<div style=\"color:white;border-radius:8px;background-color:#323232;font-size:100%\">\n",
    "<p style=\"padding: 10px;color:white;\"><b><span style='color:#B6DA32; font-weight:bold'>4.4 | WORD2VEC MODEL\n",
    "</span></b></p>\n",
    "</div>\n",
    "\n",
    "- **Word2Vec** like both methods are a \"shallow\" deep learning model, which is actually a combination of the two methods **CBOW** and **SG**\n",
    "- In practice, it is suggested to utilise the word2vec model, as it is an optimised library, wheras the two approaches above are simple implementations in Torch and Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "990f9c71",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-25T15:51:28.844656Z",
     "iopub.status.busy": "2023-05-25T15:51:28.843674Z",
     "iopub.status.idle": "2023-05-25T15:51:28.949441Z",
     "shell.execute_reply": "2023-05-25T15:51:28.948043Z"
    },
    "papermill": {
     "duration": 0.130573,
     "end_time": "2023-05-25T15:51:28.952237",
     "exception": false,
     "start_time": "2023-05-25T15:51:28.821664",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using module: nlp_embedding\n",
      "Executing Module Task: w2v\n",
      "First Tokenised corpus:\n",
      "\n",
      "['first', 'document']\n",
      "Epochs: 50\n",
      "Window: 4\n",
      "Vector Size: 5\n",
      "Vocabulary size: 7\n",
      "First 10 words in vocabulary:\n",
      "['first', 'third', 'comes', 'setence', 'second', 'following', 'document']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>first</th>\n",
       "      <td>-0.010693</td>\n",
       "      <td>0.004752</td>\n",
       "      <td>0.102105</td>\n",
       "      <td>0.180202</td>\n",
       "      <td>-0.186044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>third</th>\n",
       "      <td>-0.142342</td>\n",
       "      <td>0.129192</td>\n",
       "      <td>0.179483</td>\n",
       "      <td>-0.100311</td>\n",
       "      <td>-0.075273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>comes</th>\n",
       "      <td>0.147623</td>\n",
       "      <td>-0.030632</td>\n",
       "      <td>-0.090671</td>\n",
       "      <td>0.131107</td>\n",
       "      <td>-0.097233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>setence</th>\n",
       "      <td>-0.036320</td>\n",
       "      <td>0.057532</td>\n",
       "      <td>0.019837</td>\n",
       "      <td>-0.165704</td>\n",
       "      <td>-0.188976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>second</th>\n",
       "      <td>0.146246</td>\n",
       "      <td>0.101413</td>\n",
       "      <td>0.135164</td>\n",
       "      <td>0.015258</td>\n",
       "      <td>0.127027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>following</th>\n",
       "      <td>-0.068107</td>\n",
       "      <td>-0.018928</td>\n",
       "      <td>0.115371</td>\n",
       "      <td>-0.150433</td>\n",
       "      <td>-0.078722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>document</th>\n",
       "      <td>-0.150232</td>\n",
       "      <td>-0.018601</td>\n",
       "      <td>0.190762</td>\n",
       "      <td>-0.146383</td>\n",
       "      <td>-0.046675</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0         1         2         3         4\n",
       "first     -0.010693  0.004752  0.102105  0.180202 -0.186044\n",
       "third     -0.142342  0.129192  0.179483 -0.100311 -0.075273\n",
       "comes      0.147623 -0.030632 -0.090671  0.131107 -0.097233\n",
       "setence   -0.036320  0.057532  0.019837 -0.165704 -0.188976\n",
       "second     0.146246  0.101413  0.135164  0.015258  0.127027\n",
       "following -0.068107 -0.018928  0.115371 -0.150433 -0.078722\n",
       "document  -0.150232 -0.018601  0.190762 -0.146383 -0.046675"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.exec('word2vec embeddings using documents')\n",
    "session.glr()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31955bd0",
   "metadata": {
    "papermill": {
     "duration": 0.020098,
     "end_time": "2023-05-25T15:51:28.992746",
     "exception": false,
     "start_time": "2023-05-25T15:51:28.972648",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Four different token parameters can be utilised to control the model outcome (for all of the above)\n",
    "\n",
    "- Context window size `window`\n",
    "- Embedding dimension `dim`\n",
    "- Learning Rate `lr` \n",
    "- Number of iterations `epoch`\n",
    "\n",
    "**Tokenisation** also plays a role (as we can see from the two methods, we have different tokens), modifications of tokenisers is not curretly added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6c593337",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-25T15:51:29.035888Z",
     "iopub.status.busy": "2023-05-25T15:51:29.034931Z",
     "iopub.status.idle": "2023-05-25T15:51:29.133976Z",
     "shell.execute_reply": "2023-05-25T15:51:29.132735Z"
    },
    "papermill": {
     "duration": 0.123658,
     "end_time": "2023-05-25T15:51:29.136812",
     "exception": false,
     "start_time": "2023-05-25T15:51:29.013154",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using module: nlp_embedding\n",
      "Executing Module Task: w2v\n",
      "First Tokenised corpus:\n",
      "\n",
      "['first', 'document']\n",
      "Epochs: 50\n",
      "Window: 5\n",
      "Vector Size: 5\n",
      "Vocabulary size: 7\n",
      "First 10 words in vocabulary:\n",
      "['first', 'third', 'comes', 'setence', 'second', 'following', 'document']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>first</th>\n",
       "      <td>-0.010716</td>\n",
       "      <td>0.004735</td>\n",
       "      <td>0.102091</td>\n",
       "      <td>0.180192</td>\n",
       "      <td>-0.186115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>third</th>\n",
       "      <td>-0.142342</td>\n",
       "      <td>0.129183</td>\n",
       "      <td>0.179467</td>\n",
       "      <td>-0.100313</td>\n",
       "      <td>-0.075271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>comes</th>\n",
       "      <td>0.147605</td>\n",
       "      <td>-0.030660</td>\n",
       "      <td>-0.090721</td>\n",
       "      <td>0.131078</td>\n",
       "      <td>-0.097213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>setence</th>\n",
       "      <td>-0.036318</td>\n",
       "      <td>0.057533</td>\n",
       "      <td>0.019837</td>\n",
       "      <td>-0.165711</td>\n",
       "      <td>-0.188991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>second</th>\n",
       "      <td>0.146233</td>\n",
       "      <td>0.101414</td>\n",
       "      <td>0.135177</td>\n",
       "      <td>0.015252</td>\n",
       "      <td>0.126988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>following</th>\n",
       "      <td>-0.068108</td>\n",
       "      <td>-0.018912</td>\n",
       "      <td>0.115383</td>\n",
       "      <td>-0.150449</td>\n",
       "      <td>-0.078768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>document</th>\n",
       "      <td>-0.150232</td>\n",
       "      <td>-0.018601</td>\n",
       "      <td>0.190762</td>\n",
       "      <td>-0.146383</td>\n",
       "      <td>-0.046675</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0         1         2         3         4\n",
       "first     -0.010716  0.004735  0.102091  0.180192 -0.186115\n",
       "third     -0.142342  0.129183  0.179467 -0.100313 -0.075271\n",
       "comes      0.147605 -0.030660 -0.090721  0.131078 -0.097213\n",
       "setence   -0.036318  0.057533  0.019837 -0.165711 -0.188991\n",
       "second     0.146233  0.101414  0.135177  0.015252  0.126988\n",
       "following -0.068108 -0.018912  0.115383 -0.150449 -0.078768\n",
       "document  -0.150232 -0.018601  0.190762 -0.146383 -0.046675"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.exec('word2vec embeddings using documents window 5')\n",
    "session.glr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a218755f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-25T15:51:29.182067Z",
     "iopub.status.busy": "2023-05-25T15:51:29.180822Z",
     "iopub.status.idle": "2023-05-25T15:51:29.286347Z",
     "shell.execute_reply": "2023-05-25T15:51:29.285129Z"
    },
    "papermill": {
     "duration": 0.130974,
     "end_time": "2023-05-25T15:51:29.288758",
     "exception": false,
     "start_time": "2023-05-25T15:51:29.157784",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using module: nlp_embedding\n",
      "Executing Module Task: w2v\n",
      "First Tokenised corpus:\n",
      "\n",
      "['first', 'document']\n",
      "Epochs: 50\n",
      "Window: 4\n",
      "Vector Size: 10\n",
      "Vocabulary size: 7\n",
      "First 10 words in vocabulary:\n",
      "['first', 'third', 'comes', 'setence', 'second', 'following', 'document']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>first</th>\n",
       "      <td>-0.005384</td>\n",
       "      <td>0.002376</td>\n",
       "      <td>0.051018</td>\n",
       "      <td>0.090090</td>\n",
       "      <td>-0.093037</td>\n",
       "      <td>-0.071174</td>\n",
       "      <td>0.064576</td>\n",
       "      <td>0.089758</td>\n",
       "      <td>-0.050147</td>\n",
       "      <td>-0.037616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>third</th>\n",
       "      <td>0.073807</td>\n",
       "      <td>-0.015334</td>\n",
       "      <td>-0.045372</td>\n",
       "      <td>0.065546</td>\n",
       "      <td>-0.048608</td>\n",
       "      <td>-0.018164</td>\n",
       "      <td>0.028767</td>\n",
       "      <td>0.009926</td>\n",
       "      <td>-0.082858</td>\n",
       "      <td>-0.094493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>comes</th>\n",
       "      <td>0.073120</td>\n",
       "      <td>0.050714</td>\n",
       "      <td>0.067569</td>\n",
       "      <td>0.007648</td>\n",
       "      <td>0.063492</td>\n",
       "      <td>-0.034072</td>\n",
       "      <td>-0.009463</td>\n",
       "      <td>0.057724</td>\n",
       "      <td>-0.075237</td>\n",
       "      <td>-0.039371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>setence</th>\n",
       "      <td>-0.075116</td>\n",
       "      <td>-0.009300</td>\n",
       "      <td>0.095381</td>\n",
       "      <td>-0.073192</td>\n",
       "      <td>-0.023338</td>\n",
       "      <td>-0.019377</td>\n",
       "      <td>0.080774</td>\n",
       "      <td>-0.059309</td>\n",
       "      <td>0.000452</td>\n",
       "      <td>-0.047537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>second</th>\n",
       "      <td>-0.096043</td>\n",
       "      <td>0.050077</td>\n",
       "      <td>-0.087602</td>\n",
       "      <td>-0.043922</td>\n",
       "      <td>-0.000351</td>\n",
       "      <td>-0.002962</td>\n",
       "      <td>-0.076618</td>\n",
       "      <td>0.096155</td>\n",
       "      <td>0.049824</td>\n",
       "      <td>0.092338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>following</th>\n",
       "      <td>-0.081579</td>\n",
       "      <td>0.044958</td>\n",
       "      <td>-0.041371</td>\n",
       "      <td>0.008245</td>\n",
       "      <td>0.084986</td>\n",
       "      <td>-0.044622</td>\n",
       "      <td>0.045175</td>\n",
       "      <td>-0.067870</td>\n",
       "      <td>-0.035485</td>\n",
       "      <td>0.093985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>document</th>\n",
       "      <td>-0.015777</td>\n",
       "      <td>0.003214</td>\n",
       "      <td>-0.041406</td>\n",
       "      <td>-0.076827</td>\n",
       "      <td>-0.015080</td>\n",
       "      <td>0.024698</td>\n",
       "      <td>-0.008880</td>\n",
       "      <td>0.055337</td>\n",
       "      <td>-0.027430</td>\n",
       "      <td>0.022601</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0         1         2         3         4         5  \\\n",
       "first     -0.005384  0.002376  0.051018  0.090090 -0.093037 -0.071174   \n",
       "third      0.073807 -0.015334 -0.045372  0.065546 -0.048608 -0.018164   \n",
       "comes      0.073120  0.050714  0.067569  0.007648  0.063492 -0.034072   \n",
       "setence   -0.075116 -0.009300  0.095381 -0.073192 -0.023338 -0.019377   \n",
       "second    -0.096043  0.050077 -0.087602 -0.043922 -0.000351 -0.002962   \n",
       "following -0.081579  0.044958 -0.041371  0.008245  0.084986 -0.044622   \n",
       "document  -0.015777  0.003214 -0.041406 -0.076827 -0.015080  0.024698   \n",
       "\n",
       "                  6         7         8         9  \n",
       "first      0.064576  0.089758 -0.050147 -0.037616  \n",
       "third      0.028767  0.009926 -0.082858 -0.094493  \n",
       "comes     -0.009463  0.057724 -0.075237 -0.039371  \n",
       "setence    0.080774 -0.059309  0.000452 -0.047537  \n",
       "second    -0.076618  0.096155  0.049824  0.092338  \n",
       "following  0.045175 -0.067870 -0.035485  0.093985  \n",
       "document  -0.008880  0.055337 -0.027430  0.022601  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.exec('word2vec embeddings using documents dim 10')\n",
    "session.glr()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 61.335946,
   "end_time": "2023-05-25T15:51:32.180783",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-05-25T15:50:30.844837",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
